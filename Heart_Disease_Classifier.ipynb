{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHLpomKEUDx8",
        "outputId": "d1da5f44-39ff-40c0-9b3c-0b91f164656d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'classifier__C': 1, 'classifier__solver': 'lbfgs'}\n",
            "Accuracy on test set: 0.8833\n",
            "Confusion Matrix:\n",
            "[[32  4]\n",
            " [ 3 21]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        36\n",
            "           1       0.84      0.88      0.86        24\n",
            "\n",
            "    accuracy                           0.88        60\n",
            "   macro avg       0.88      0.88      0.88        60\n",
            "weighted avg       0.88      0.88      0.88        60\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Column names according to dataset documentation\n",
        "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
        "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "\n",
        "# Load data\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
        "df = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Replace missing value placeholders '?' with NaN\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Convert columns with missing values to numeric\n",
        "for col in ['ca', 'thal']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# The target is 0 (no disease) and 1-4 (presence of disease), convert >1 to 1\n",
        "df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Identify numerical and categorical features\n",
        "categorical_features = ['cp', 'restecg', 'slope', 'thal', 'ca']\n",
        "numerical_features = ['age', 'sex', 'trestbps', 'chol', 'fbs', 'thalach', 'exang', 'oldpeak']\n",
        "\n",
        "# Create a preprocessor to apply different transformations\n",
        "# StandardScaler is for numerical data, passthrough for categorical\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', 'passthrough', categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Create a pipeline to streamline the workflow\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'classifier__solver': ['liblinear', 'lbfgs']     # Solver for optimization\n",
        "}\n",
        "\n",
        "# Set up cross-validation using StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform a grid search to find the best model\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the best model from the grid search on the training data\n",
        "best_model = grid_search.fit(X_train, y_train).best_estimator_\n",
        "\n",
        "# Make predictions and evaluate the final model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ]
}